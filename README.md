# ðŸ§  SmartDoc Assistant

SmartDoc Assistant is a GenAI-powered document comprehension tool that helps users:

- ðŸ“„ Summarize uploaded PDFs or TXT documents  
- â“ Ask contextual questions based on the uploaded document  
- ðŸ§  Take auto-generated quizzes to test understanding  

---

## âœ¨ Features

# ðŸ“„ Upload Documents
- Upload .pdf or .txt files for intelligent analysis.
# ðŸ§  AI-Powered Summarization
- Generate concise summaries of uploaded documents using LLMs.
# â“ Ask Contextual Questions
- Ask questions based on document content.
- Remembers context from previously asked questions.
- Option to reset context anytime.
- Stores and displays previous questions in the UI.
# ðŸ§© Generate Logic-Based Quizzes
- Automatically generate quiz questions that require reasoning and inference.
# âœ… Evaluate Quiz Answers
- Get feedback with grades, justifications, and concise insights based on your answers.
# ðŸ’¾ Local Upload History
- Persists previously uploaded files via localStorage.
- View all uploaded documents in the sidebar.
- Delete individual files by clicking âŒ.
-Clear all files with a single click. 

---

## ðŸ§± Architecture & Reasoning Flow

Frontend (React) â—„â”€â”€â”€â–º Backend (FastAPI)

User Uploads File â”€â”€â”€â”€â”€â–º /upload
â””â”€â–º Extracts, chunks & indexes text
â””â”€â–º Embeds chunks for retrieval

User Asks Question â”€â”€â”€â”€â”€â–º /ask
â””â”€â–º Retrieves relevant chunks
â””â”€â–º Constructs prompt with context & history
â””â”€â–º Calls LLM (local or remote)

Generate Quiz â”€â”€â”€â”€â”€â–º /quiz/generate
â””â”€â–º Context-based question generation (LLM)

Evaluate Answers â”€â”€â”€â”€â”€â–º /quiz/evaluate
â””â”€â–º Feedback per answer using LLM

---


> ðŸ§  Uses embedding-based chunk retrieval for contextual Q&A and quiz generation. Context + session history helps create accurate prompts.

---

## âš™ï¸ Tech Stack

| Layer       | Tech                             |
|-------------|----------------------------------|
| Frontend    | React + CSS      |
| Backend     | FastAPI                          |
| Embedding   | SentenceTransformers / HF Models |
| LLM         | Local LLM with Ollama            |
| Storage     | Browser LocalStorage             |
| PDF Parsing | PyMuPDF / pdfminer               |

---

## ðŸš€ Setup Instructions

1ï¸âƒ£ Clone the Repository
git clone https://github.com/SurajitM0nd0l/SmartDoc-Assistant.git
cd SmartDoc-Assistant

2ï¸âƒ£ Backend Setup(/backend)
cd backend

Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

Install dependencies
pip install -r requirements.txt

Start FastAPI server
uvicorn main:app --reload
Runs at http://localhost:8000

3ï¸âƒ£ Frontend Setup (/frontend)
cd ../frontend

Install dependencies
npm install

Create .env file
echo "VITE_API_BASE_URL=http://localhost:8000" > .env

Start React app
npm run dev
Runs at http://localhost:5173


## ðŸ§° Local LLM with Ollama

1. Install Ollama: 
Go to ollama.com/download and install for macOS, Windows, or Linux.
Verify installation:
ollama --version

3. Pull a Model: 
ollama pull mistral

5. Run the Model: 
ollama run mistral

## ðŸ§ª Example Workflow

Upload a research paper (PDF/TXT)
View the AI-generated summary
Ask contextual questions (e.g., "What is the core contribution?")
Generate a quiz â†’ Submit answers â†’ Receive intelligent feedback
